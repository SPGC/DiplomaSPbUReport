\section{Анализ литературы}
\subsection{Введение}
Поскольку задача была разбита на два этапа, то и анализ литературы производился в два этапа:
\begin{enumerate}
    \item Методы сегментации, не использующие глубокое обучение
    \item Методы сегментации, использующие глубокое обучение
\end{enumerate}

Однако оба анализа ставили целью найти подходы, использующие алгоритмы без размеченных датасетов.

\subsection{Методы сегментации, не использующие глубокое обучение}
Для сегментации изображений без использования глубокого обучения было решено обратить внимание на классические методы кластеризации, 
такие как KMeans\cite{kmeans}, DBSCAN\cite{dbscan} и EM\cite{em1} алгоритмы, поскольку сегментация в данном подходе будет в основном зависеть от цвета пикселей.

После проведенных экспериментов было решено остановится на EM алгоритме. DBSCAN не представлялось возможным использовать из-за скорости его работы, в то время 
как KMeans не сегментировал изображение так, как это было необходимо.

\subsection{Методы сегментации, использующие глубокое обучение}
Для данного подхода вариативность была куда больше. 
Рассматривались разные подходы к обучению без датасетов, такие как:
\begin{enumerate}
    \item STEGO\cite{stego} данный подход обучает сеть на основе похожести изображений. В сеть подается само изображение, его ближайший сосед и случайное изображение, 
    после чего на основе схожести выходов бэкбоуна данной сети, а также итоговых меток для изображения, его ближайшего соседа и случайного изображения считается лосс, 
    на основе которого и происходит обучение сети. В качестве метрики схожести изображений используется архитектура DINO. Эта статья побудила к использованию DINO в данной работе.
    \item IIC\cite{iic} эта архитектура обучает сеть на основе информационного критерия, сети подаются на вход изображения и их измененные версии. 
    После чего считается информационный критерий и его максимизация является процессом обучения данной архитектуры. Сеть с использованием такого к подхода к обучению 
    была опробована, но, к сожалению, она не дала тех результатов, которые получились в итоге.
    \item DFC\cite{dfc} данный подход напоминает EM алгоритм, который в деталях описан в следующей главе. Идея DFC состоит в том, чтобы выдать метки классов, затем на основе 
    этих псевдометок обновить веса сети, после чего повторить процесс несколько раз. Данный подход также был опробован, но он оказался, во-первых, слишком медленным, а
    во-вторых не выдавал маску того же качества, как реализованный алгоритм 
    \item DINO\cite{DINO} эта архитектура подробно описана в главе ниже, она используется как часть архитектуры итоговой сети.
\end{enumerate}
Некоторые из подходов, описанных выше использовали бэкбоуны (в частности STEGO~\cite{stego}), поэтому было решено исследовать и вопрос обучения бэкбоуна для извлечения 
признаков из изображения. 
\begin{enumerate}
    \item Избавление от шума\cite{denoise}
    \item Решение пазлов\cite{puzzles}
    \item Восстановление части изображения\cite{drawing_backbone}
    \item Предсказание поворота\cite{rotation_prediction}
    \item Использование аугментаций для создания бэкбоуна\cite{augmentations_learning}
\end{enumerate}

\subsection{Итог}
После анализа литературы было принято решение не использовать готовую сеть, а реализовать свою архитектуру. Данное решение продиктовано тем, что рассмотренные подходы
обучались для сегментации и классификации множества различных классов, в то время как сеть для БИК требует возможности сегментации всего на три весьма похожих класса. 
Поэтому рассмотренные выше подходы являлись либо не такими точными, либо избыточными, а в следствие этого тяжелыми с точки зрения вычислений.
Предложенная в этой архитектура нейронной сети представляет собой результат синтеза некоторых идей из упомянутых выше статей и классических подходов в компьютерном зрении.
